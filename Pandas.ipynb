{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Data with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "\n",
    "* Understand the role of `pandas` in the Python ecosystem.\n",
    "* Read a flat file (CSV) dataset into Python with `pandas`.\n",
    "* Understand the basic features of a `DataFrame`.\n",
    "* Employ slicing to select subsets of data from a `DataFrame`.\n",
    "* Use label- and integer-based indexing to select ranges of data in a `DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "Data Scientists spend an incredible amount of time and skills acquiring, prepping, cleaning, and normalizing data. In this workshops, we'll review one of the most important tools used during this process, `pandas`. \n",
    "\n",
    "But first, let's review the differences between Data Acquisition, Preparation, and Cleaning.\n",
    "\n",
    "### Data Acquisition\n",
    "\n",
    "Many times, your data might be already given to you, in which case you won't have to worry about data acquisition. However, this is not always the case. The process of actually getting a dataset to work with is called **data acquisition**. For the purposes of this tutorial, we won't be providing an in-depth review of data acquisition methodology, but this should provide some context as to how `pandas` fits into the data science ecosystem. \n",
    "\n",
    "### Data Preparation\n",
    "\n",
    "Now, once a dataset is acquired, it might not be in a suitable format to work with. In some cases, you might have scraped data from a website or simply downloaded a zipfile containing multiple CSV files. Luckily, `pandas` provides Python users with an important data type you can use to work with data in an easy manner. This process of converting data into a suitable format is called **data preparation**.\n",
    "\n",
    "\n",
    "### Data Cleaning\n",
    "\n",
    "Now that your data is being handled in a proper manner, your work with it still might not be done. You might have missing values, values that need normalizing, or values in the wrong data type. These inconsistencies that you fix before analysis refers to **data cleaning**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "Now that we've reviewed the process in which `pandas` fits in as a Python tool, we will begin to review pandas and its different capabilities. \n",
    "\n",
    "Pandas allows us to deal with data in a user-friendly way by providing with an important data type, referred to as a `DataFrame`, not otherwise available in Python. With `pandas` we can effortlessly import data from files such as CSVs into a DataFrame object, allowing us to quickly apply transformations, filters, and other data wrangling methodology to our data.\n",
    "\n",
    "To begin this tutorial, we'll need to first import `pandas`. Typically, the shorthand alias used is `pd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n",
    "\n",
    "Before we review the DataFrame object in `pandas`, we'll begin by reviewing the `series` data type. \n",
    "\n",
    "In its simplest form, a Series is a one-dimensional object containing an array of data. Below, you'll see that we use the `pandas.Series()` function to define an example containing 4 numbers. Notice that the input of this method *is* a Python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series([4, 7, -5, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series are incredibly similar to your typical list in Python, however, it **is** distinctive, which we can display by printing the data type of the series below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(obj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason for this distinction is because `pandas` allows us to attach our own custom indices, as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d    4\n",
      "b    7\n",
      "a   -5\n",
      "c    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "obj2 = pd.Series([4, 7, -5, 3], index=['d', 'b', 'a', 'c'])\n",
    "print(obj2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might be thinking, \"is this not the same thing as a dictionary?\", a fair question for anyone beginning to learn `pandas`. Now, the useful thing is that we can, indeed, easily convert a dictionary to a series, as you can see in the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = {'Ohio': 35000, 'Texas': 71000, 'Oregon': 16000, 'Utah': 5000}\n",
    "obj3 = pd.Series(sdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But notice that if the actual object is printed, as well as its type, the format is much more readable with the series object. This is incredibly useful for when a user needs to visually interact with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(sdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(obj3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(obj3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames\n",
    "\n",
    "Now that we've reviewed the simplest object in `pandas`, we're ready to tackle on the DataFrame object. A DataFrame represents a tabular, spreadsheet-like data structure containing an ordered collection of columns, each of which can be a different value type (numeric, string, boolean, etc.).\n",
    "\n",
    "There are numerous ways to construct a DataFrame, though one of the most common is from a dict of equal-length lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'], 'year': [2000, 2001, 2002, 2001, 2002], 'pop': [1.5, 1.7, 3.6, 2.4, 2.9]}\n",
    "frame = pd.DataFrame(data)\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select a single column, the syntax is treated the same way you would a dictionary, with brackets inside which contains the column name. \n",
    "\n",
    "It's important to note that DataFrames are actually a collection of `series`, which we can see is true when we index one of the columns and print its type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = frame['state']\n",
    "print(type(sel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Question\n",
    "\n",
    "True or False: Series and Dictionaries can converted to one another with one simple function call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Files\n",
    "\n",
    "It was briefly mentioned earlier that one of the advantages of Python is to easily convert a CSV file to a pandas DataFrame. \n",
    "\n",
    "Using [this](https://s3.amazonaws.com/assets.datacamp.com/production/course_1639/datasets/world_ind_pop_data.csv) csv file, which is population data from the World Bank, we'll use pandas to convert this file to a DataFrame -- all in two lines of code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'https://s3.amazonaws.com/assets.datacamp.com/production/course_1639/datasets/world_ind_pop_data.csv'\n",
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, we used the built-in pandas function, `read_csv()` to input the file into Python. Just to confirm that the file was properly converted into a DataFrame, let's take a look at what the data type is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we used the `type()` method to check the data type of our converted CSV file, but `pandas` actually provides users with an `info()` function to display a concise summary of a given DataFrame. Let's take a look at what `pandas` has to say about the World Bank dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13374 entries, 0 to 13373\n",
      "Data columns (total 5 columns):\n",
      "CountryName                      13374 non-null object\n",
      "CountryCode                      13374 non-null object\n",
      "Year                             13374 non-null int64\n",
      "Total Population                 13374 non-null float64\n",
      "Urban population (% of total)    13374 non-null float64\n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 522.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very first line, as you can see, tells us what type it is -- awesome. Additionally, we have useful information involving the size of the data, the data types of each column, and more. This is a wonderful substitute to having to call different methods like `len()`, `type()`, etc., on our DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unless you opened up the link provided above, you've likely not seen what the actual data looks like. To fix that, you can utilize another crucial method of `pandas` called `head()`. As default it prints the column names and the first five rows of the DataFrame you call the method on, but if you want to adjust the number, you can feed it whatever number you'd like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the opposite end, you can also display the last 10 rows of a given DataFrame as well, using the `tail()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountryName</th>\n",
       "      <th>CountryCode</th>\n",
       "      <th>Year</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Urban population (% of total)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13364</th>\n",
       "      <td>Uruguay</td>\n",
       "      <td>URY</td>\n",
       "      <td>2014</td>\n",
       "      <td>3419516.0</td>\n",
       "      <td>95.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13365</th>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>UZB</td>\n",
       "      <td>2014</td>\n",
       "      <td>30757700.0</td>\n",
       "      <td>36.278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13366</th>\n",
       "      <td>Vanuatu</td>\n",
       "      <td>VUT</td>\n",
       "      <td>2014</td>\n",
       "      <td>258883.0</td>\n",
       "      <td>25.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13367</th>\n",
       "      <td>Venezuela, RB</td>\n",
       "      <td>VEN</td>\n",
       "      <td>2014</td>\n",
       "      <td>30693827.0</td>\n",
       "      <td>88.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13368</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>VNM</td>\n",
       "      <td>2014</td>\n",
       "      <td>90730000.0</td>\n",
       "      <td>32.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13369</th>\n",
       "      <td>Virgin Islands (U.S.)</td>\n",
       "      <td>VIR</td>\n",
       "      <td>2014</td>\n",
       "      <td>104170.0</td>\n",
       "      <td>95.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13370</th>\n",
       "      <td>West Bank and Gaza</td>\n",
       "      <td>WBG</td>\n",
       "      <td>2014</td>\n",
       "      <td>4294682.0</td>\n",
       "      <td>75.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13371</th>\n",
       "      <td>Yemen, Rep.</td>\n",
       "      <td>YEM</td>\n",
       "      <td>2014</td>\n",
       "      <td>26183676.0</td>\n",
       "      <td>34.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13372</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>2014</td>\n",
       "      <td>15721343.0</td>\n",
       "      <td>40.472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13373</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>2014</td>\n",
       "      <td>15245855.0</td>\n",
       "      <td>32.501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 CountryName CountryCode  Year  Total Population  \\\n",
       "13364                Uruguay         URY  2014         3419516.0   \n",
       "13365             Uzbekistan         UZB  2014        30757700.0   \n",
       "13366                Vanuatu         VUT  2014          258883.0   \n",
       "13367          Venezuela, RB         VEN  2014        30693827.0   \n",
       "13368                Vietnam         VNM  2014        90730000.0   \n",
       "13369  Virgin Islands (U.S.)         VIR  2014          104170.0   \n",
       "13370     West Bank and Gaza         WBG  2014         4294682.0   \n",
       "13371            Yemen, Rep.         YEM  2014        26183676.0   \n",
       "13372                 Zambia         ZMB  2014        15721343.0   \n",
       "13373               Zimbabwe         ZWE  2014        15245855.0   \n",
       "\n",
       "       Urban population (% of total)  \n",
       "13364                         95.152  \n",
       "13365                         36.278  \n",
       "13366                         25.817  \n",
       "13367                         88.941  \n",
       "13368                         32.951  \n",
       "13369                         95.203  \n",
       "13370                         75.026  \n",
       "13371                         34.027  \n",
       "13372                         40.472  \n",
       "13373                         32.501  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier in this tutorial, we selected a column from the DataFrame we built using a dictionary. The same can be done an **any** DataFrame, including those which began as a CSV file. With that said, we'll review an example by selecting the `Total Population` column from the World Bank dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Total Population'].head()) # called the head function so we don't have to view the entire column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've reviewed how to select columns from DataFrames, how do we go about selecting *rows* from a DataFrame? \n",
    "\n",
    "A simple way is to use the built-in `ix` function, which can take either a single parameter to select **1** row, or it can take in a range using list slicing rules you've seen in regular Python lists. \n",
    "\n",
    "Below we'll print 5 rows using this method: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.ix[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply\n",
    "\n",
    "Lets's generate a random dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "frame = pd.DataFrame(np.random.randn(4, 3), columns=list('bde'), index=['Utah', 'Ohio', 'Texas', 'Oregon'])\n",
    "\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we can apply a function on a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also apply functions with the `apply()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: x.max() - x.min()\n",
    "\n",
    "print(frame.apply(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: np.abs(x)\n",
    "\n",
    "frame.apply(f)\n",
    "\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Question \n",
    "\n",
    "Does the `pandas.DataFrame.apply()` function modify the original DataFrame or return a new DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting\n",
    "\n",
    "To sort lexicographically by row or column index, use the sort_index method, which returns a new, sorted object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Merging\n",
    "\n",
    "If you encounter two different datasets that contain the same type of information, you might consider merging them for your analyses. This is yet another functionality built into `pandas`. \n",
    "\n",
    "Let's go through an example containing student data. `d1` contains 5 of the samples and `d2` contains 2 of them: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.read_csv(\"./names_original.csv\")\n",
    "print(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(d1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = pd.read_csv(\"./names_add.csv\")\n",
    "print(d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenation \n",
    "\n",
    "Instead of working with two separate datasets, it's much easier to simply merge, so we do this with the `concat()` function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([d1,d2])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you might be asking what will happen if one of the datasets has more columns than other - will they still be allowed to merge? Let's try this example with another dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3 = pd.read_csv(\"./names_extra.csv\")\n",
    "print(d3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use the same `concat()` function, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = pd.concat([d1, d3])\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the `NaN` values - these are undefined values indicating there wasn't any data to be displayed. `pandas` will simply fill in the missing data for each sample where it's unavailable:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Question\n",
    "\n",
    "Does the `pandas.DataFrame.concat()` function modify a original DataFrame or return a new DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging\n",
    "\n",
    "Now, how do we merge two datasets with differing columns? Well, let's take a look at our datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = pd.read_csv(\"./housing.csv\")\n",
    "print(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2 = pd.read_csv(\"./dorms.csv\")\n",
    "print(h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `merge()` function in pandas, we can specify which column to merge on and what kind of join to specify. By default merge does an 'inner' join, but here we set it to a left join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house = pd.merge(h1, h2, on=\"Dorm\", how=\"left\")\n",
    "print(house)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Question\n",
    "\n",
    "Does the `pandas.DataFrame.merge()` function modify a original DataFrame or return a new DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Resources\n",
    "\n",
    "[Pandas Learning Resources](https://chatbotslife.com/pandas-learning-resources-946540ba574e) <br>\n",
    "[GeoPandas Tutorial](https://www.twilio.com/blog/2017/08/geospatial-analysis-python-geojson-geopandas.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
